"""
Hybrid Backlink Analyzer V2
Ø§Ø¯ØºØ§Ù… SeleniumBase + SE Ranking + Ahrefs Fallbacks
"""

from typing import List, Dict, Optional
import time

# SE Ranking API
from backlink_module import BacklinkAnalyzer

# SeleniumBase scraper
try:
    from ahrefs_seleniumbase import scrape_ahrefs_seleniumbase
    SELENIUMBASE_AVAILABLE = True
except ImportError:
    SELENIUMBASE_AVAILABLE = False
    print("âš ï¸ SeleniumBase Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install seleniumbase")


class HybridBacklinkAnalyzerV2:
    """
    ØªØ±Ú©ÛŒØ¨ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú†Ù†Ø¯ Ù…Ù†Ø¨Ø¹ Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©
    
    Ø§ÙˆÙ„ÙˆÛŒØª:
    1. Ahrefs (SeleniumBase) - Ø±Ø§ÛŒÚ¯Ø§Ù†ØŒ 80-90% Ù…ÙˆÙÙ‚ÛŒØª
    2. SE Ranking API - Ù¾ÙˆÙ„ÛŒØŒ 100% Ù…ÙˆÙÙ‚ÛŒØª
    3. Fallback strategies
    """
    
    def __init__(
        self,
        prefer_ahrefs: bool = False,
        use_seleniumbase: bool = True,
        headless: bool = False
    ):
        """
        Args:
            prefer_ahrefs: Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ahrefs ÛŒØ§ SE Ranking
            use_seleniumbase: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SeleniumBase Ø¨Ø±Ø§ÛŒ Ahrefs
            headless: Ù…Ø±ÙˆØ±Ú¯Ø± Ù…Ø®ÙÛŒ (Ø¨Ø±Ø§ÛŒ production)
        """
        self.se_ranking = BacklinkAnalyzer()
        self.prefer_ahrefs = prefer_ahrefs
        self.use_seleniumbase = use_seleniumbase and SELENIUMBASE_AVAILABLE
        self.headless = headless
        
        if not SELENIUMBASE_AVAILABLE and use_seleniumbase:
            print("âš ï¸ SeleniumBase Ù†ØµØ¨ Ù†ÛŒØ³Øª - ÙÙ‚Ø· Ø§Ø² SE Ranking Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
            self.use_seleniumbase = False
    
    def fetch_links(
        self,
        domain: str,
        limit: int = 100,
        fallback: bool = True,
        ahrefs_wait_time: int = 10
    ) -> List[Dict]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú© Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯
        
        Args:
            domain: Ø¯Ø§Ù…Ù†Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
            limit: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©
            fallback: Ø§Ú¯Ø± Ù…Ù†Ø¨Ø¹ Ø§ÙˆÙ„ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ Ø§Ø² Ø¯ÛŒÚ¯Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯
            ahrefs_wait_time: Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ahrefs (Ø«Ø§Ù†ÛŒÙ‡)
        
        Returns:
            Ù„ÛŒØ³Øª Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©â€ŒÙ‡Ø§
        """
        backlinks = []
        
        # ØªØ¹ÛŒÛŒÙ† Ø§ÙˆÙ„ÙˆÛŒØª Ù…Ù†Ø§Ø¨Ø¹
        if self.prefer_ahrefs and self.use_seleniumbase:
            primary = "ahrefs_seleniumbase"
            secondary = "se_ranking"
        else:
            primary = "se_ranking"
            secondary = "ahrefs_seleniumbase" if self.use_seleniumbase else None
        
        print(f"ğŸ¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ: Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ {primary}")
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ Ù…Ù†Ø¨Ø¹ Ø§ÙˆÙ„
        backlinks = self._fetch_from_source(
            domain,
            primary,
            limit,
            ahrefs_wait_time
        )
        
        # Fallback Ø¨Ù‡ Ù…Ù†Ø¨Ø¹ Ø¯ÙˆÙ…
        if fallback and len(backlinks) < 10 and secondary:
            print(f"âš ï¸ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù… ({len(backlinks)}). ØªÙ„Ø§Ø´ Ø¨Ø§ {secondary}...")
            
            secondary_links = self._fetch_from_source(
                domain,
                secondary,
                limit,
                ahrefs_wait_time
            )
            
            # ØªØ±Ú©ÛŒØ¨ Ù†ØªØ§ÛŒØ¬
            backlinks = self._merge_backlinks(backlinks, secondary_links)
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ limit
        return backlinks[:limit]
    
    def _fetch_from_source(
        self,
        domain: str,
        source: str,
        limit: int,
        ahrefs_wait_time: int
    ) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² ÛŒÚ© Ù…Ù†Ø¨Ø¹ Ø®Ø§Øµ"""
        
        try:
            if source == "ahrefs_seleniumbase" and self.use_seleniumbase:
                print(f"ğŸ¦Š Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ahrefs (SeleniumBase UC mode)...")
                
                backlinks = scrape_ahrefs_seleniumbase(
                    domain=domain,
                    headless=self.headless,
                    wait_time=ahrefs_wait_time
                )
                
                # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ù…Øª (ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯)
                return self._normalize_ahrefs_format(backlinks)
            
            elif source == "se_ranking":
                print(f"ğŸ” Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² SE Ranking API...")
                return self.se_ranking.fetch_links(domain, limit=limit)
            
            else:
                print(f"âš ï¸ Ù…Ù†Ø¨Ø¹ {source} Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
                return []
        
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² {source}: {e}")
            return []
    
    def _normalize_ahrefs_format(self, ahrefs_data: List[Dict]) -> List[Dict]:
        """ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª Ahrefs Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        normalized = []
        
        for link in ahrefs_data:
            try:
                # Ø§Ú¯Ø± Ø§Ø² Ù‚Ø¨Ù„ normalized Ø´Ø¯Ù‡
                if "domain_inlink_rank" in link:
                    normalized.append(link)
                    continue
                
                # ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª
                normalized.append({
                    "url_from": link.get("url_from", "N/A"),
                    "url_to": link.get("url_to", "N/A"),
                    "anchor": link.get("anchor", "N/A"),
                    "nofollow": 1 if link.get("nofollow") else 0,
                    "domain_inlink_rank": link.get("domain_rating", "N/A"),
                    "first_seen": "N/A",
                    "source": link.get("source", "ahrefs"),
                    "inlink_rank": "N/A",
                    "page_inlink_rank": "N/A",
                })
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ: {e}")
                continue
        
        return normalized
    
    def _merge_backlinks(self, list1: List[Dict], list2: List[Dict]) -> List[Dict]:
        """ØªØ±Ú©ÛŒØ¨ Ø¯Ùˆ Ù„ÛŒØ³Øª Ùˆ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§"""
        merged = list1.copy()
        seen_urls = {link.get("url_from") for link in list1 if link.get("url_from")}
        
        for link in list2:
            url_from = link.get("url_from")
            if url_from and url_from not in seen_urls and url_from != "N/A":
                merged.append(link)
                seen_urls.add(url_from)
        
        return merged
    
    def fetch_with_quality_score(
        self,
        domain: str,
        limit: int = 100,
        ahrefs_wait_time: int = 10
    ) -> List[Dict]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª
        """
        print(f"\nğŸ”¬ ØªØ­Ù„ÛŒÙ„ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø±Ø§ÛŒ {domain}...")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ù…Ù†Ø¨Ø¹ (Ø§Ú¯Ø± Ù…Ù…Ú©Ù† Ø¨Ø§Ø´Ø¯)
        all_backlinks = []
        
        if self.use_seleniumbase:
            ahrefs_links = self._fetch_from_source(
                domain,
                "ahrefs_seleniumbase",
                limit,
                ahrefs_wait_time
            )
            all_backlinks.extend(ahrefs_links)
            time.sleep(2)
        
        se_links = self._fetch_from_source(domain, "se_ranking", limit, 0)
        all_backlinks.extend(se_links)
        
        # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒ
        merged = self._merge_backlinks([], all_backlinks)
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Quality Score
        for link in merged:
            link["quality_score"] = self._calculate_quality_score(link)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
        merged.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
        
        print(f"âœ… Ú©Ù„ Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©â€ŒÙ‡Ø§: {len(merged)}")
        
        return merged[:limit]
    
    def _calculate_quality_score(self, link: Dict) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ú©ÛŒÙÛŒØª"""
        score = 0.0
        
        # Domain Rating
        dr = link.get("domain_inlink_rank", "N/A")
        if dr != "N/A":
            try:
                score += float(dr) * 2
            except:
                pass
        
        # Dofollow
        if link.get("nofollow") == 0:
            score += 20
        
        # Anchor Text
        anchor = link.get("anchor", "")
        if anchor and anchor != "N/A" and len(anchor) > 3:
            score += 10
        
        # Source bonus
        source = link.get("source", "")
        if "ahrefs" in source:
            score += 5
        
        return score


# =====================================
# Helper Functions Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø³Ø§Ù†
# =====================================

def get_backlinks_hybrid(
    domain: str,
    use_ahrefs: bool = True,
    headless: bool = False,
    limit: int = 100
) -> List[Dict]:
    """
    Helper function Ø³Ø§Ø¯Ù‡
    
    Args:
        domain: Ø¯Ø§Ù…Ù†Ù‡
        use_ahrefs: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ahrefs SeleniumBase
        headless: Ù…Ø±ÙˆØ±Ú¯Ø± Ù…Ø®ÙÛŒ
        limit: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯
    
    Returns:
        Ù„ÛŒØ³Øª Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    """
    analyzer = HybridBacklinkAnalyzerV2(
        prefer_ahrefs=use_ahrefs,
        use_seleniumbase=use_ahrefs,
        headless=headless
    )
    
    return analyzer.fetch_links(domain, limit=limit, fallback=True)


# =====================================
# ØªØ³Øª
# =====================================
if __name__ == "__main__":
    print("="*70)
    print("ğŸ”¥ HYBRID BACKLINK ANALYZER V2")
    print("="*70)
    print("\nÙ…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯:")
    print("  âœ… SE Ranking API")
    if SELENIUMBASE_AVAILABLE:
        print("  âœ… Ahrefs (SeleniumBase UC mode)")
    else:
        print("  âŒ Ahrefs (Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install seleniumbase)")
    print("="*70 + "\n")
    
    domain = input("ğŸ”‘ Ø¯Ø§Ù…Ù†Ù‡: ").strip() or "example.com"
    
    use_ahrefs = input("ğŸ¦Š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ahrefs? (y/n) [y]: ").strip().lower()
    use_ahrefs = use_ahrefs != 'n'
    
    # ØªØ³Øª
    analyzer = HybridBacklinkAnalyzerV2(
        prefer_ahrefs=use_ahrefs,
        use_seleniumbase=use_ahrefs,
        headless=False
    )
    
    backlinks = analyzer.fetch_links(domain, limit=50, fallback=True)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š Ù†ØªÛŒØ¬Ù‡: {len(backlinks)} Ø¨Ú©â€ŒÙ„ÛŒÙ†Ú©")
    print("="*70)
    
    if backlinks:
        print("\nâœ… Ù†Ù…ÙˆÙ†Ù‡:")
        for i, link in enumerate(backlinks[:5], 1):
            print(f"\n{i}. {link.get('url_from', 'N/A')}")
            print(f"   Anchor: {link.get('anchor', 'N/A')[:50]}")
            print(f"   Source: {link.get('source', 'N/A')}")
            print(f"   Quality Score: {link.get('quality_score', 0):.1f}")
